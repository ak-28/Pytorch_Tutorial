{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Python Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: torch.Size([4])\n",
      "Matrix shape: torch.Size([2, 3])\n",
      "3D tensor shape: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# From lists\n",
    "vector = torch.tensor([1, 2, 3, 4])\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "print(f\"Vector shape: {vector.shape}\")\n",
    "print(f\"Matrix shape: {matrix.shape}\")\n",
    "print(f\"3D tensor shape: {tensor_3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original numpy array: [1 2 3]\n",
      "tensor from numpy: tensor([1, 2, 3])\n",
      "tensor_copy: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.array([1,2,3])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "tensor_copy = torch.tensor(numpy_array)\n",
    "\n",
    "\n",
    "print(f\"original numpy array: {numpy_array}\")\n",
    "print(f\"tensor from numpy: {tensor_from_numpy}\")\n",
    "print(f\"tensor_copy: {tensor_copy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Tensor Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8164, 0.9770, 0.0129, 0.2732],\n",
       "        [0.5355, 0.8141, 0.6632, 0.0899]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4059, -0.7304, -2.4784,  0.0544],\n",
       "        [ 0.0829, -2.9344,  0.8752, -0.1511]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard normal\n",
    "torch.randn(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 2, 0],\n",
       "        [1, 3, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random intergers, low,high, size\n",
    "torch.randint(0,4,(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.5000, 7.5000, 7.5000],\n",
       "        [7.5000, 7.5000, 7.5000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filled with specific values\n",
    "torch.full((2,3), 7.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5714, 2.1429, 2.7143, 3.2857, 3.8571, 4.4286, 5.0000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linearly spaced\n",
    "torch.linspace(1,5,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.randn(3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_shape: torch.Size([3, 4, 5])\n",
      "data type: torch.float32\n",
      "Device: cpu\n",
      ":Requires Gradient False\n",
      "Number or elements: 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor_shape: {tensor.shape}\")\n",
    "print(f\"data type: {tensor.dtype}\")\n",
    "print(f\"Device: {tensor.device}\")\n",
    "print(f\":Requires Gradient {tensor.requires_grad}\")\n",
    "print(f\"Number or elements: {tensor.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations: Beyond NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add1: tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "add2: tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "add3: tensor([[ 6,  8],\n",
      "        [10, 12]])\n"
     ]
    }
   ],
   "source": [
    "add1 = a + b\n",
    "add2 = torch.add(a,b)\n",
    "add3 = a.add(b)\n",
    "\n",
    "print(f\"add1: {add1}\")\n",
    "print(f\"add2: {add2}\")\n",
    "print(f\"add3: {add3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 14],\n",
       "        [17, 20]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled additions\n",
    "\n",
    "scaled_add = torch.add(a,b, alpha=2) # a+2*b\n",
    "scaled_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul1:tensor([[-2.6480, -0.3734, -3.7430, -1.8007, -1.9437],\n",
      "        [-1.9674, -0.6171, -0.6695,  2.1408, -2.4892],\n",
      "        [-1.3993, -0.3063, -1.0599, -0.2092,  0.6514]])\n",
      "matmul2:tensor([[-2.6480, -0.3734, -3.7430, -1.8007, -1.9437],\n",
      "        [-1.9674, -0.6171, -0.6695,  2.1408, -2.4892],\n",
      "        [-1.3993, -0.3063, -1.0599, -0.2092,  0.6514]])\n",
      "matmul3:tensor([[-2.6480, -0.3734, -3.7430, -1.8007, -1.9437],\n",
      "        [-1.9674, -0.6171, -0.6695,  2.1408, -2.4892],\n",
      "        [-1.3993, -0.3063, -1.0599, -0.2092,  0.6514]])\n",
      "element wise:tensor([[1.6167e+00, 3.6401e+00, 1.0368e-05, 9.8502e-03],\n",
      "        [1.3825e+00, 7.5347e-02, 1.5675e+00, 3.4820e+00],\n",
      "        [9.3346e-02, 1.1520e-03, 2.6908e+00, 2.6431e-01]])\n"
     ]
    }
   ],
   "source": [
    "matmul1 = x.matmul(y)\n",
    "matmul2 = x @ y\n",
    "matmul3 = torch.mm(x,y) # only for 2-D tensors\n",
    "\n",
    "element_wise = x * x\n",
    "\n",
    "print(f\"matmul1:{matmul1}\")\n",
    "print(f\"matmul2:{matmul2}\")\n",
    "print(f\"matmul3:{matmul3}\")\n",
    "print(f\"element wise:{element_wise}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[[-0.1618, -0.7268,  0.9754, -0.5236,  1.6792],\n",
      "         [-0.8890,  1.1406, -0.9529, -0.6271,  1.3454],\n",
      "         [ 0.6099,  0.5167, -0.1132,  0.6841, -1.2386],\n",
      "         [-1.1246, -0.1782,  2.2038,  0.0100, -0.2533]],\n",
      "\n",
      "        [[-0.0679,  0.5993, -1.0563, -0.0331,  0.7992],\n",
      "         [-2.2053,  1.4867, -0.5018,  0.2173,  1.3603],\n",
      "         [-1.1327, -0.4020, -1.0862, -0.8179, -1.9508],\n",
      "         [-1.3342, -1.6493, -0.6656,  1.4484,  0.4194]],\n",
      "\n",
      "        [[ 0.2422, -0.1554,  0.5541,  0.2547,  0.3117],\n",
      "         [-1.0611,  3.0310, -1.9969, -0.8493,  2.8213],\n",
      "         [-1.1637, -0.7653,  2.0314, -1.2741,  0.8449],\n",
      "         [ 1.4980, -1.5383,  0.9549,  0.2376, -0.1333]]])\n",
      "Original shape: torch.Size([3, 4, 5])\n",
      "Sum along dim 0: torch.Size([4, 5])\n",
      "Sum along multiple dims: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "# Global reductions\n",
    "total_sum = torch.sum(tensor)\n",
    "mean_value = torch.mean(tensor)\n",
    "max_value = torch.max(tensor)\n",
    "\n",
    "# Dimension-specific reductions\n",
    "sum_dim0 = torch.sum(tensor, dim=0)  # Shape: [4, 5]\n",
    "sum_dim1 = torch.sum(tensor, dim=1)  # Shape: [3, 5]\n",
    "\n",
    "# Multiple dimensions\n",
    "sum_dims = torch.sum(tensor, dim=[0, 2])  # Shape: [4]\n",
    "\n",
    "print(f\"Original: {tensor}\")\n",
    "print(f\"Original shape: {tensor.shape}\")\n",
    "print(f\"Sum along dim 0: {sum_dim0.shape}\")\n",
    "print(f\"Sum along multiple dims: {sum_dims.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.3520), tensor(3.0310))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0125, -0.2829,  0.4732, -0.3020,  2.7901],\n",
       "        [-4.1554,  5.6583, -3.4517, -1.2591,  5.5270],\n",
       "        [-1.6865, -0.6506,  0.8320, -1.4079, -2.3445],\n",
       "        [-0.9607, -3.3657,  2.4931,  1.6960,  0.0328]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dim0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5654,  0.7524,  2.1131, -0.4566,  1.5327],\n",
       "        [-4.7402,  0.0347, -3.3100,  0.8147,  0.6281],\n",
       "        [-0.4846,  0.5720,  1.5435, -1.6312,  3.8447]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.6909,  2.3191, -5.2574, -0.1046])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_tensor = torch.randn(3, 3)\n",
    "gpu_tensor = torch.randn(3, 3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU tensor device: cpu\n",
      "GPU tensor device: cuda:0\n",
      "moved tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "moved_tensor = cpu_tensor.to(device)\n",
    "\n",
    "print(f\"CPU tensor device: {cpu_tensor.device}\")\n",
    "print(f\"GPU tensor device: {gpu_tensor.device}\")\n",
    "print(f\"moved tensor device: {moved_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice: device-agnostic code\n",
    "def create_model_tensors(device):\n",
    "    weights = torch.randn(100, 50, device=device)\n",
    "    bias = torch.zeros(50, device=device)\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 1024\n"
     ]
    }
   ],
   "source": [
    "# Memory management for GPUs\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large tensor device: cuda:0\n",
      "Computation result shape: torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "large_tensor = torch.randn(1000, 1000, device = 'cuda')\n",
    "result = torch.matmul(large_tensor, large_tensor.T)\n",
    "\n",
    "print(f\"Large tensor device: {large_tensor.device}\")\n",
    "print(f\"Computation result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20972544"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Type\t        PyTorch dtype\t                    Typical Use Case\n",
    "# 32-bit float\t    torch.float32 or torch.float\t    Default for neural networks, models, gradients\n",
    "# 64-bit float\t    torch.float64 or torch.double\t    High-precision scientific computing\n",
    "# 16-bit float\t    torch.float16 or torch.half\t        Memory-efficient training\n",
    "# 64-bit integer\ttorch.int64 or torch.long\t        Default for indices, labels, counts\n",
    "# 32-bit integer\ttorch.int32 or torch.int\t        Smaller integer operations\n",
    "# Boolean\t        torch.bool\t                        Masks, conditions\n",
    "\n",
    "\n",
    "# The fundamental tension comes from PyTorch's defaults:\n",
    "\n",
    "# Floating-point tensors default to float32 - perfect for neural network computations\n",
    "\n",
    "# Integer tensors default to int64 - suitable for indexing and labels\n",
    "\n",
    "# These don't mix automatically - leading to type mismatch errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will cause a type error\n",
    "predictions = torch.randn(10, 5)  # float32\n",
    "labels = torch.randint(0, 5, (10,))  # int64\n",
    "\n",
    "# CrossEntropyLoss expects float32 predictions and int64 labels - this works\n",
    "loss = torch.nn.CrossEntropyLoss()(predictions, labels)\n",
    "\n",
    "# But BCELoss expects both to be float32 - this fails\n",
    "binary_labels = torch.randint(0, 2, (10,))  # int64\n",
    "# loss = torch.nn.BCELoss()(predictions, binary_labels)  # ERROR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor = torch.randn(3, 3)  # float32\n",
    "int_tensor = torch.randint(0, 10, (3, 3))  # int64\n",
    "\n",
    "# Basic arithmetic works due to type promotion\n",
    "result = float_tensor + int_tensor  # Works - promotes to float32\n",
    "\n",
    "# But matrix multiplication is stricter\n",
    "# result = torch.matmul(float_tensor, int_tensor)  # ERROR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch's Type Promotion Rules\n",
    "# PyTorch does have limited automatic type promotion, but it's much more restrictive than NumPy:\n",
    "\n",
    "# Promotion Hierarchy: complex ← float ← int ← bool\n",
    "\n",
    "# Higher priority types dominate (float beats int, complex beats float)\n",
    "\n",
    "# Same category, different sizes promote to larger size\n",
    "\n",
    "# Different categories follow the hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic promotion examples\n",
    "bool_tensor = torch.tensor([True, False])     # bool\n",
    "int_tensor = torch.tensor([1, 2])             # int64\n",
    "float_tensor = torch.tensor([1.0, 2.0])       # float32\n",
    "\n",
    "# These work due to promotion\n",
    "bool_plus_int = bool_tensor + int_tensor       # → int64\n",
    "int_plus_float = int_tensor + float_tensor     # → float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_plus_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_plus_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ways to cast types\n",
    "int_tensor = torch.randint(0, 10, (3, 3))\n",
    "\n",
    "# Method 1: Using .to()\n",
    "float_version = int_tensor.to(torch.float32)\n",
    "\n",
    "# Method 2: Using dtype-specific methods\n",
    "float_version = int_tensor.float()\n",
    "\n",
    "# Method 3: During tensor creation\n",
    "# float_tensor = torch.tensor(data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory and Performance Considerations\n",
    "# Type choice affects performance and memory usage:\n",
    "\n",
    "# float32 - Good balance for most deep learning (4 bytes per element)\n",
    "\n",
    "# float16 - Half precision, saves memory but may lose precision (2 bytes per element)\n",
    "\n",
    "# float64 - Double precision, uses more memory (8 bytes per element)\n",
    "\n",
    "# int64 - Default for indices, may be overkill for small datasets (8 bytes per element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
